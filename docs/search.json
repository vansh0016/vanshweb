[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Codes",
    "section": "",
    "text": "library(ggplot2)     # Loads ggplot2\nlibrary(tidyverse)   # Loads tidyverse\nlibrary(plotly)      # Loads plotly\nlibrary(scales)      # Loads scales\n\nworld_population &lt;- read.csv(\"world_population.csv\")  # Reads the data into a data frame\n\nworld_population &lt;- world_population %&gt;%\n  rename(country = `Country.Territory`,  # Renames 'Country.Territory' to 'country'\n         capital = `Capital`,              # Renames 'Capital' to 'capital'\n         population_2020 = `X2020.Population`)  # Renames 'X2020.Population' to 'population_2020'\n\nplot &lt;- plot_ly(\n  data = world_population,  # Uses the cleaned world_population dataset\n  type = 'choropleth',      # Specifies the type of plot as a choropleth map\n  locations = world_population$CCA3,  # Assigns country codes (CCA3) for geographical locations\n  z = world_population$population_2020,  # Sets the population values for color intensity\n  text = paste(\"Country:\", world_population$country,  # Creates hover text to show detailed information\n               \"&lt;br&gt;Capital:\", world_population$capital,\n               \"&lt;br&gt;Population:\", world_population$population_2020,\n               \"&lt;br&gt;Population Percentage:\", world_population$World.Population.Percentage),\n  hoverinfo = \"text\",  # Displays the detailed hover text when the user hovers over a country\n  colorscale = list(c(0, \"lightblue\"), c(1, \"darkblue\")),  # Defines a color scale from light blue to dark blue\n  colorbar = list(title = \"Population\"),  # Labels the color bar indicating the population scale\n  marker = list(line = list(color = 'black', width = 0.5))  # Sets the border color and width for each country\n) %&gt;%\nlayout(\n    title = 'World Population',  # Sets the main title of the plot\n    geo = list(\n      showframe = FALSE,  # Hides the frame around the map for a cleaner look\n      showcoastlines = TRUE,  # Enables coastlines to help delineate country borders\n      coastlinecolor = 'Black',  # Sets the color of the coastlines to black\n      projection = list(type = 'Mercator'),  # Uses Mercator projection for accurate representation of landmasses\n      showland = TRUE,  # Ensures that land areas are displayed on the map\n      landcolor = 'lightgrey',  # Sets the color of land areas to light grey for contrast\n      subunitcolor = 'black'  # Sets the color of subunit borders (countries) to black for visibility\n    )\n)\n\nplot  # Displays the plot\n\n\n\n\n\nworld_population2 &lt;- read.csv(\"world_population.csv\")  # Loads the dataset\n\nlong_population_data &lt;- world_population2 %&gt;%\n  select(`Country.Territory`,  # Selects the country territory column\n         `X2022.Population`,   # Selects the population for 2022\n         `X2020.Population`,   # Selects the population for 2020\n         `X2015.Population`,   # Selects the population for 2015\n         `X2010.Population`,   # Selects the population for 2010\n         `X2000.Population`,   # Selects the population for 2000\n         `X1990.Population`,   # Selects the population for 1990\n         `X1980.Population`,   # Selects the population for 1980\n         `X1970.Population`) %&gt;%  # Selects the population for 1970\n  pivot_longer(cols = starts_with(\"X\"),  # Reshapes the data to long format for years\n               names_to = \"Year\",  # Sets the name for the year column\n               values_to = \"Population\") %&gt;%  # Sets the name for the population column\n  mutate(Year = gsub(\"X\", \"\", Year),  # Removes \"X\" from the year values\n         Year = gsub(\"\\\\.Population\", \"\", Year))  # Removes \".Population\" from the year values\n\ntop_ten_countries &lt;- world_population2 %&gt;%\n  arrange(desc(`X2020.Population`)) %&gt;%  # Arranges the countries in descending order by 2020 population\n  head(10) %&gt;%  # Selects the top ten countries\n  pull(`Country.Territory`)  # Extracts the country names\n\nfiltered_data &lt;- long_population_data %&gt;%\n  filter(`Country.Territory` %in% top_ten_countries)  # Filters data for the top ten countries\n\nplots_list &lt;- list()  # Creates an empty list to hold plot objects\n\nfor (country in unique(filtered_data$`Country.Territory`)) {\n  country_data &lt;- filtered_data %&gt;% filter(`Country.Territory` == country)  # Filter data for the current country\n\n  plot &lt;- plot_ly(data = country_data,\n                  x = ~Year,  # Sets the x-axis to the Year\n                  y = ~Population,  # Sets the y-axis to Population\n                  type = 'scatter',  # Specifies the plot type as scatter\n                  mode = 'lines+markers',  # Uses lines and markers for the plot\n                  name = country,  # Labels the plot with the country's name\n                  text = ~paste(\"Population:\", Population),  # Creates hover text showing population\n                  hoverinfo = 'text') %&gt;%  # Ensures hover info displays the text\n    layout(title = country,  # Sets the title of the plot to the country's name\n           xaxis = list(title = \"Year\"),  # Labels the x-axis\n           yaxis = list(title = \"Population\"),  # Labels the y-axis\n           showlegend = FALSE)  # Disables the legend for individual country plots\n\n  plots_list[[country]] &lt;- plot  # Adds the plot to the list using the country name as the key\n}\n\ncombined_plot &lt;- subplot(plots_list, nrows = 2, shareX = TRUE, titleX = TRUE, titleY = TRUE) %&gt;%\n  layout(title = \"Change in Population of Top 10 Countries Over Years\",  # Sets the main title for the combined plot\n         xaxis = list(title = \"Year\"),  # Labels the x-axis for the combined plot\n         yaxis = list(title = \"Population\"),  # Labels the y-axis for the combined plot\n         showlegend = TRUE)  # Enables the legend for the combined plot\n\ncombined_plot  # Displays the final combined plot of population changes\n\n\n\n\n\n\n\n\nlibrary(ggplot2)  # Loads ggplot2\nlibrary(plotly)   # Loads plotly\nlibrary(dplyr)    # Loads dplyr\n\nBook1 &lt;- read.csv(\"Book1.csv\")  # Loads the data into a data frame\n\nBook1 &lt;- Book1 %&gt;%\n  rename(\n    State = State,  # Renames State column to State\n    Gun.Ownership.Rate = `Gun.Ownership.Rate....`,  # Renames gun ownership rate column\n    Suicidal.Rate.Per.100000 = `Suicidal.rate..per.100.000.`  # Renames suicidal rate column\n  )\n\nscatter_plot &lt;- ggplot(Book1, aes(x = Gun.Ownership.Rate, y = Suicidal.Rate.Per.100000, color = State)) +\n  geom_point(size = 3, alpha = 0.7) +  # Adds points for each state with specified size and transparency\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +  # Adds a dashed regression line without confidence intervals\n  labs(title = \"Gun Ownership vs Suicidal Rate by State\",  # Sets the main title of the plot\n       x = \"Gun Ownership Rate (%)\",  # Labels the x-axis\n       y = \"Suicidal Rate\") +  # Labels the y-axis\n  theme(legend.position = \"none\")  # Hides the legend\n\ninteractive_plot &lt;- ggplotly(scatter_plot)  # Creates an interactive version of the scatter plot\n\ninteractive_plot  # Renders the interactive plot for user interaction\n\n\n\n\n\nlibrary(reshape2)  # Loads reshape2\nlibrary(ggplot2)   # Loads ggplot2\n\nBook1 &lt;- read.csv(\"Book1.csv\")  # Loads the data into a data frame\n\nBook1 &lt;- Book1 %&gt;%\n  rename(\n    State = State,  # Renames State column to State\n    Gun.Ownership.Rate = `Gun.Ownership.Rate....`,  # Renames gun ownership rate column\n    Suicidal.Rate.Per.100000 = `Suicidal.rate..per.100.000.`  # Renames suicidal rate column\n  )\n\ndf_long &lt;- melt(Book1, id.vars = \"State\", measure.vars = c(\"Suicidal.Rate.Per.100000\", \"Gun.Ownership.Rate\"))  # Melts the data frame\n\ncolnames(df_long) &lt;- c(\"State\", \"Metric\", \"Value\")  # Updates column names\n\ndf_long$Metric &lt;- factor(df_long$Metric, levels = c(\"Gun.Ownership.Rate\", \"Suicidal.Rate.Per.100000\"))  # Sets order for plotting\n\ntotal_values &lt;- df_long %&gt;%\n  group_by(State) %&gt;%\n  summarise(Total = sum(Value, na.rm = TRUE))  # Summarizes total values by state, ignoring NAs\n\ndf_long &lt;- df_long %&gt;%\n  left_join(total_values, by = \"State\") %&gt;%\n  arrange(Total)  # Arranges data by total value in ascending order\n\nggplot(df_long, aes(x = reorder(State, Total), y = Value, fill = Metric)) +  # Initializes ggplot with specified aesthetics\n  geom_bar(stat = \"identity\", na.rm = TRUE) +  # Creates bars using the identity statistic, ignoring missing values\n  geom_text(aes(label = round(Value, 1)), position = position_stack(vjust = 0.5), size = 2, na.rm = TRUE) +  # Adds text labels inside the bars\n  scale_fill_manual(values = c(\"Suicidal.Rate.Per.100000\" = \"red\", \"Gun.Ownership.Rate\" = \"skyblue\"),  # Defines colors for the metrics\n                    labels = c(\"Suicidal.Rate.Per.100000\" = \"Suicidal Rate\",  # Custom legend labels\n                               \"Gun.Ownership.Rate\" = \"Gun Ownership Rate\")) +\n  labs(title = \"Stacked Bar Plot of Gun Ownership Rate and Suicidal Rate by State\",  # Sets the plot title\n       x = \"State\",  # Labels the x-axis\n       y = \"Rate\",  # Labels the y-axis\n       fill = \"Metric\") +  # Labels the fill legend\n  theme(axis.text.x = element_text(angle = 0, size = 8)) +  # Customizes x-axis text appearance\n  coord_flip()  # Flips the coordinates for better readability\n\n\n\n\n\n\n\n\nlibrary(ggplot2)  # Loads ggplot2\nlibrary(tidyverse)  # Loads tidyverse\n\ndebatestats &lt;- read.csv(\"PDebate.csv\")  # Loads the data into a data frame\n\nlong_debatestats &lt;- debatestats %&gt;%\n  pivot_longer(cols = c(Trump, Biden),  # Specifies the columns to pivot\n               names_to = \"candidate\",  # New column to hold candidate names\n               values_to = \"score\")  # New column to hold the scores (time in minutes)\n\n ggplot(long_debatestats, aes(x = Topic, y = score, fill = candidate)) +  # Initializes ggplot with specified aesthetics\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Creates stacked bars using the identity statistic\n  scale_fill_manual(values = c(\"Biden\" = \"blue\", \"Trump\" = \"red\")) +  # Defines colors for each candidate\n  geom_text(aes(label = score), position = position_stack(vjust = 0.5), color = \"white\") +  # Adds text labels showing the score inside the bars\n  labs(title = \"Debate Stats: Trump vs Biden by Topic\",  # Sets the plot title\n       x = \"Topic\",  # Labels the x-axis\n       y = \"Time (mins)\",  # Labels the y-axis indicating time in minutes\n       fill = \"Candidate\")  # Labels the fill legend for candidate colors"
  },
  {
    "objectID": "code.html#population-in-one-chart",
    "href": "code.html#population-in-one-chart",
    "title": "Codes",
    "section": "",
    "text": "library(ggplot2)     # Loads ggplot2\nlibrary(tidyverse)   # Loads tidyverse\nlibrary(plotly)      # Loads plotly\nlibrary(scales)      # Loads scales\n\nworld_population &lt;- read.csv(\"world_population.csv\")  # Reads the data into a data frame\n\nworld_population &lt;- world_population %&gt;%\n  rename(country = `Country.Territory`,  # Renames 'Country.Territory' to 'country'\n         capital = `Capital`,              # Renames 'Capital' to 'capital'\n         population_2020 = `X2020.Population`)  # Renames 'X2020.Population' to 'population_2020'\n\nplot &lt;- plot_ly(\n  data = world_population,  # Uses the cleaned world_population dataset\n  type = 'choropleth',      # Specifies the type of plot as a choropleth map\n  locations = world_population$CCA3,  # Assigns country codes (CCA3) for geographical locations\n  z = world_population$population_2020,  # Sets the population values for color intensity\n  text = paste(\"Country:\", world_population$country,  # Creates hover text to show detailed information\n               \"&lt;br&gt;Capital:\", world_population$capital,\n               \"&lt;br&gt;Population:\", world_population$population_2020,\n               \"&lt;br&gt;Population Percentage:\", world_population$World.Population.Percentage),\n  hoverinfo = \"text\",  # Displays the detailed hover text when the user hovers over a country\n  colorscale = list(c(0, \"lightblue\"), c(1, \"darkblue\")),  # Defines a color scale from light blue to dark blue\n  colorbar = list(title = \"Population\"),  # Labels the color bar indicating the population scale\n  marker = list(line = list(color = 'black', width = 0.5))  # Sets the border color and width for each country\n) %&gt;%\nlayout(\n    title = 'World Population',  # Sets the main title of the plot\n    geo = list(\n      showframe = FALSE,  # Hides the frame around the map for a cleaner look\n      showcoastlines = TRUE,  # Enables coastlines to help delineate country borders\n      coastlinecolor = 'Black',  # Sets the color of the coastlines to black\n      projection = list(type = 'Mercator'),  # Uses Mercator projection for accurate representation of landmasses\n      showland = TRUE,  # Ensures that land areas are displayed on the map\n      landcolor = 'lightgrey',  # Sets the color of land areas to light grey for contrast\n      subunitcolor = 'black'  # Sets the color of subunit borders (countries) to black for visibility\n    )\n)\n\nplot  # Displays the plot\n\n\n\n\n\nworld_population2 &lt;- read.csv(\"world_population.csv\")  # Loads the dataset\n\nlong_population_data &lt;- world_population2 %&gt;%\n  select(`Country.Territory`,  # Selects the country territory column\n         `X2022.Population`,   # Selects the population for 2022\n         `X2020.Population`,   # Selects the population for 2020\n         `X2015.Population`,   # Selects the population for 2015\n         `X2010.Population`,   # Selects the population for 2010\n         `X2000.Population`,   # Selects the population for 2000\n         `X1990.Population`,   # Selects the population for 1990\n         `X1980.Population`,   # Selects the population for 1980\n         `X1970.Population`) %&gt;%  # Selects the population for 1970\n  pivot_longer(cols = starts_with(\"X\"),  # Reshapes the data to long format for years\n               names_to = \"Year\",  # Sets the name for the year column\n               values_to = \"Population\") %&gt;%  # Sets the name for the population column\n  mutate(Year = gsub(\"X\", \"\", Year),  # Removes \"X\" from the year values\n         Year = gsub(\"\\\\.Population\", \"\", Year))  # Removes \".Population\" from the year values\n\ntop_ten_countries &lt;- world_population2 %&gt;%\n  arrange(desc(`X2020.Population`)) %&gt;%  # Arranges the countries in descending order by 2020 population\n  head(10) %&gt;%  # Selects the top ten countries\n  pull(`Country.Territory`)  # Extracts the country names\n\nfiltered_data &lt;- long_population_data %&gt;%\n  filter(`Country.Territory` %in% top_ten_countries)  # Filters data for the top ten countries\n\nplots_list &lt;- list()  # Creates an empty list to hold plot objects\n\nfor (country in unique(filtered_data$`Country.Territory`)) {\n  country_data &lt;- filtered_data %&gt;% filter(`Country.Territory` == country)  # Filter data for the current country\n\n  plot &lt;- plot_ly(data = country_data,\n                  x = ~Year,  # Sets the x-axis to the Year\n                  y = ~Population,  # Sets the y-axis to Population\n                  type = 'scatter',  # Specifies the plot type as scatter\n                  mode = 'lines+markers',  # Uses lines and markers for the plot\n                  name = country,  # Labels the plot with the country's name\n                  text = ~paste(\"Population:\", Population),  # Creates hover text showing population\n                  hoverinfo = 'text') %&gt;%  # Ensures hover info displays the text\n    layout(title = country,  # Sets the title of the plot to the country's name\n           xaxis = list(title = \"Year\"),  # Labels the x-axis\n           yaxis = list(title = \"Population\"),  # Labels the y-axis\n           showlegend = FALSE)  # Disables the legend for individual country plots\n\n  plots_list[[country]] &lt;- plot  # Adds the plot to the list using the country name as the key\n}\n\ncombined_plot &lt;- subplot(plots_list, nrows = 2, shareX = TRUE, titleX = TRUE, titleY = TRUE) %&gt;%\n  layout(title = \"Change in Population of Top 10 Countries Over Years\",  # Sets the main title for the combined plot\n         xaxis = list(title = \"Year\"),  # Labels the x-axis for the combined plot\n         yaxis = list(title = \"Population\"),  # Labels the y-axis for the combined plot\n         showlegend = TRUE)  # Enables the legend for the combined plot\n\ncombined_plot  # Displays the final combined plot of population changes"
  },
  {
    "objectID": "code.html#relationship-between-gun-ownership-and-suicide-rate",
    "href": "code.html#relationship-between-gun-ownership-and-suicide-rate",
    "title": "Codes",
    "section": "",
    "text": "library(ggplot2)  # Loads ggplot2\nlibrary(plotly)   # Loads plotly\nlibrary(dplyr)    # Loads dplyr\n\nBook1 &lt;- read.csv(\"Book1.csv\")  # Loads the data into a data frame\n\nBook1 &lt;- Book1 %&gt;%\n  rename(\n    State = State,  # Renames State column to State\n    Gun.Ownership.Rate = `Gun.Ownership.Rate....`,  # Renames gun ownership rate column\n    Suicidal.Rate.Per.100000 = `Suicidal.rate..per.100.000.`  # Renames suicidal rate column\n  )\n\nscatter_plot &lt;- ggplot(Book1, aes(x = Gun.Ownership.Rate, y = Suicidal.Rate.Per.100000, color = State)) +\n  geom_point(size = 3, alpha = 0.7) +  # Adds points for each state with specified size and transparency\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +  # Adds a dashed regression line without confidence intervals\n  labs(title = \"Gun Ownership vs Suicidal Rate by State\",  # Sets the main title of the plot\n       x = \"Gun Ownership Rate (%)\",  # Labels the x-axis\n       y = \"Suicidal Rate\") +  # Labels the y-axis\n  theme(legend.position = \"none\")  # Hides the legend\n\ninteractive_plot &lt;- ggplotly(scatter_plot)  # Creates an interactive version of the scatter plot\n\ninteractive_plot  # Renders the interactive plot for user interaction\n\n\n\n\n\nlibrary(reshape2)  # Loads reshape2\nlibrary(ggplot2)   # Loads ggplot2\n\nBook1 &lt;- read.csv(\"Book1.csv\")  # Loads the data into a data frame\n\nBook1 &lt;- Book1 %&gt;%\n  rename(\n    State = State,  # Renames State column to State\n    Gun.Ownership.Rate = `Gun.Ownership.Rate....`,  # Renames gun ownership rate column\n    Suicidal.Rate.Per.100000 = `Suicidal.rate..per.100.000.`  # Renames suicidal rate column\n  )\n\ndf_long &lt;- melt(Book1, id.vars = \"State\", measure.vars = c(\"Suicidal.Rate.Per.100000\", \"Gun.Ownership.Rate\"))  # Melts the data frame\n\ncolnames(df_long) &lt;- c(\"State\", \"Metric\", \"Value\")  # Updates column names\n\ndf_long$Metric &lt;- factor(df_long$Metric, levels = c(\"Gun.Ownership.Rate\", \"Suicidal.Rate.Per.100000\"))  # Sets order for plotting\n\ntotal_values &lt;- df_long %&gt;%\n  group_by(State) %&gt;%\n  summarise(Total = sum(Value, na.rm = TRUE))  # Summarizes total values by state, ignoring NAs\n\ndf_long &lt;- df_long %&gt;%\n  left_join(total_values, by = \"State\") %&gt;%\n  arrange(Total)  # Arranges data by total value in ascending order\n\nggplot(df_long, aes(x = reorder(State, Total), y = Value, fill = Metric)) +  # Initializes ggplot with specified aesthetics\n  geom_bar(stat = \"identity\", na.rm = TRUE) +  # Creates bars using the identity statistic, ignoring missing values\n  geom_text(aes(label = round(Value, 1)), position = position_stack(vjust = 0.5), size = 2, na.rm = TRUE) +  # Adds text labels inside the bars\n  scale_fill_manual(values = c(\"Suicidal.Rate.Per.100000\" = \"red\", \"Gun.Ownership.Rate\" = \"skyblue\"),  # Defines colors for the metrics\n                    labels = c(\"Suicidal.Rate.Per.100000\" = \"Suicidal Rate\",  # Custom legend labels\n                               \"Gun.Ownership.Rate\" = \"Gun Ownership Rate\")) +\n  labs(title = \"Stacked Bar Plot of Gun Ownership Rate and Suicidal Rate by State\",  # Sets the plot title\n       x = \"State\",  # Labels the x-axis\n       y = \"Rate\",  # Labels the y-axis\n       fill = \"Metric\") +  # Labels the fill legend\n  theme(axis.text.x = element_text(angle = 0, size = 8)) +  # Customizes x-axis text appearance\n  coord_flip()  # Flips the coordinates for better readability"
  },
  {
    "objectID": "code.html#presidential-debate",
    "href": "code.html#presidential-debate",
    "title": "Codes",
    "section": "",
    "text": "library(ggplot2)  # Loads ggplot2\nlibrary(tidyverse)  # Loads tidyverse\n\ndebatestats &lt;- read.csv(\"PDebate.csv\")  # Loads the data into a data frame\n\nlong_debatestats &lt;- debatestats %&gt;%\n  pivot_longer(cols = c(Trump, Biden),  # Specifies the columns to pivot\n               names_to = \"candidate\",  # New column to hold candidate names\n               values_to = \"score\")  # New column to hold the scores (time in minutes)\n\n ggplot(long_debatestats, aes(x = Topic, y = score, fill = candidate)) +  # Initializes ggplot with specified aesthetics\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Creates stacked bars using the identity statistic\n  scale_fill_manual(values = c(\"Biden\" = \"blue\", \"Trump\" = \"red\")) +  # Defines colors for each candidate\n  geom_text(aes(label = score), position = position_stack(vjust = 0.5), color = \"white\") +  # Adds text labels showing the score inside the bars\n  labs(title = \"Debate Stats: Trump vs Biden by Topic\",  # Sets the plot title\n       x = \"Topic\",  # Labels the x-axis\n       y = \"Time (mins)\",  # Labels the y-axis indicating time in minutes\n       fill = \"Candidate\")  # Labels the fill legend for candidate colors"
  },
  {
    "objectID": "FinalProject.html",
    "href": "FinalProject.html",
    "title": "Final Project",
    "section": "",
    "text": "id project.code           pq..   po...so..  asn.dn..       country\n19 81483   108-VN-T30      FPQ-10286 SCMS-156150 ASN-16914       Vietnam\n21    92   102-NG-T01 Pre-PQ Process    SCMS-592   ASN-485       Nigeria\n23   108   104-CI-T01 Pre-PQ Process    SCMS-698   ASN-727 Côte d'Ivoire\n24   115   108-VN-T01 Pre-PQ Process    SCMS-753   ASN-781       Vietnam\n25   116   108-VN-T01 Pre-PQ Process    SCMS-759   ASN-632       Vietnam\n26   130   100-HT-T01 Pre-PQ Process  SCMS-10080   ASN-628         Haiti\n   managed.by fulfill.via vendor.inco.term shipment.mode\n19   PMO - US Direct Drop              EXW           Air\n21   PMO - US Direct Drop              EXW           Air\n23   PMO - US Direct Drop              CIP           Air\n24   PMO - US Direct Drop              EXW           Air\n25   PMO - US Direct Drop              FCA           Air\n26   PMO - US Direct Drop              EXW           Air\n   pq.first.sent.to.client.date po.sent.to.vendor.date scheduled.delivery.date\n19                    7/25/2012              8/15/2012               12-Nov-12\n21               Pre-PQ Process              5/13/2007               19-Jun-07\n23               Pre-PQ Process              7/13/2007                2-Oct-07\n24               Pre-PQ Process               7/4/2007               15-Oct-07\n25               Pre-PQ Process               7/4/2007               27-Aug-07\n26               Pre-PQ Process              7/26/2007               13-Aug-07\n   delivered.to.client.date delivery.recorded.date product.group\n19                12-Nov-12              12-Nov-12           ARV\n21                19-Jun-07              19-Jun-07          HRDT\n23                 2-Oct-07               2-Oct-07           ARV\n24                15-Oct-07              15-Oct-07           ARV\n25                27-Aug-07              27-Aug-07           ARV\n26                21-Aug-07              21-Aug-07          HRDT\n   sub.classification                                          vendor\n19              Adult                                   CIPLA LIMITED\n21           HIV test                            Abbott GmbH & Co. KG\n23          Pediatric                            BRISTOL-MYERS SQUIBB\n24          Pediatric                        Aurobindo Pharma Limited\n25              Adult ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV)\n26           HIV test                                   Orgenics, Ltd\n                                           item.description\n19                       Zidovudine 300mg, tablets, 60 Tabs\n21           HIV 1/2, Determine Complete HIV Kit, 100 Tests\n23      #102198**Didanosine 200mg [Videx], tablets, 60 Tabs\n24      Nevirapine 10mg/ml, oral suspension, Bottle, 240 ml\n25 Lopinavir/Ritonavir 200/50mg [Aluvia], tablets, 120 Tabs\n26   HIV 1/2, Determine HIV Kit, without Lancets, 100 Tests\n                            molecule.test.type     brand   dosage\n19                                  Zidovudine   Generic    300mg\n21         HIV 1/2, Determine Complete HIV Kit Determine         \n23                                  Didanosine     Videx    200mg\n24                                  Nevirapine   Generic  10mg/ml\n25                         Lopinavir/Ritonavir    Aluvia 200/50mg\n26 HIV 1/2, Determine HIV Kit, without Lancets Determine         \n       dosage.form unit.of.measure..per.pack. line.item.quantity\n19          Tablet                         60                525\n21        Test kit                        100               1000\n23          Tablet                         60               5513\n24 Oral suspension                        240               1000\n25          Tablet                        120                500\n26        Test kit                        100                750\n   line.item.value pack.price unit.price            manufacturing.site\n19          3465.0       6.60       0.11             Cipla, Goa, India\n21         80000.0      80.00       0.80 ABBVIE GmbH & Co.KG Wiesbaden\n23        140581.5      25.50       0.42            BMS Meymac, France\n24          1920.0       1.92       0.01     Aurobindo Unit III, India\n25         41095.0      82.19       0.68   ABBVIE Ludwigshafen Germany\n26         53992.5      71.99       0.72               Inverness Japan\n   first.line.designation weight..kilograms.                 freight.cost..usd.\n19                   true                 34                             807.47\n21                   true                341                            2682.47\n23                   true               2126 Freight Included in Commodity Cost\n24                   true                941                            4193.49\n25                   true                117                            1767.38\n26                   true                171                            3518.38\n   line.item.insurance..usd. freight_cost_usd weight_kilograms\n19                      4.86          807.470               34\n21                    128.00         2682.470              341\n23                    224.93         5869.655             2126\n24                      3.07         4193.490              941\n25                     65.75         1767.380              117\n26                     86.39         3518.380              171\n\n\nThe dataset focuses on supply chain operations, capturing details about shipments, associated costs, and product characteristics. Key variables include freight_cost_usd, representing freight costs in USD, and line.item.insurance..usd., indicating the insurance cost for line items. Shipment details such as the shipment.mode (e.g., air, sea, or road) and the destination country are included, alongside product-related variables like product.group, sub.classification, line.item.quantity, and line.item.value. Additionally, weight_kilograms captures the shipment weight, while pack.price provides the price per package. The dataset includes both numerical and categorical variables, requiring preprocessing to ensure consistency and readiness for analysis.\n\n\n\nThe dataset underwent extensive cleaning steps to ensure quality and usability for analysis. Non-numeric entries in freight.cost..usd. and weight..kilograms. were identified and replaced with NA, followed by the removal of unwanted characters to standardize these columns as numeric. Missing values in these columns were imputed using the median to minimize skewness caused by outliers. Rows with empty shipment.mode or missing values in line.item.insurance..usd. were excluded to maintain data completeness. Relevant columns were selected for analysis, and categorical variables such as shipment.mode, country, product.group, and sub.classification were encoded as numeric features using factor. A custom function was applied to remove outliers by filtering values outside the 1st and 99th percentiles for key numeric variables, including freight_cost_usd, weight_kilograms, line.item.quantity, and line.item.value. Additionally, line.item.insurance..usd. was categorized into three levels (low, medium, and high) using quantile-based thresholds. The dosage column was standardized by extracting numeric values and imputing missing entries with 0, followed by outlier removal. Delivery dates were converted to Date objects, and a new column, delivery_time, was created to calculate the number of days between scheduled and actual delivery dates, leading to the categorization of delivery outcomes as “Early,” “On Time,” or “Late.” Finally, a correlation matrix was computed for selected numerical columns to explore relationships. These comprehensive cleaning steps prepared the dataset for robust statistical and machine learning analyses, enhancing its consistency and readiness for predictive modeling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe correlation matrix reveals the relationships between various numerical variables in the dataset, highlighting both strong and weak associations. Among the notable findings, line.item.insurance..usd. shows a very strong positive correlation with line.item.value (0.96) and a strong correlation with line.item.quantity (0.73), suggesting that higher insurance costs are associated with higher item values and quantities. freight_cost_usd is moderately correlated with line.item.insurance..usd. (0.36) and weight_kilograms (0.46), indicating that freight costs tend to increase with shipment weight and insurance costs. In contrast, pack.price exhibits minimal correlations with most variables, except for a moderate positive correlation with product_group_encoded (0.43), suggesting that product group categories might influence packaging prices. Negative correlations are observed in some cases; for example, product_group_encoded and line.item.quantity (-0.20) as well as sub_classification_encoded and line.item.value (-0.25) indicate slight inverse relationships. Weak or negligible correlations are seen with shipment_mode_encoded and most variables, such as freight_cost_usd (-0.07) and line.item.value (0.11), suggesting minimal influence of shipment mode on these attributes. Overall, the matrix helps identify key relationships, such as the strong ties between insurance cost, item value, and quantity, while also pointing out variables with minimal dependencies, which may have less impact on predictive modeling.\n\n\n\nCall:\nlm(formula = line.item.insurance..usd. ~ freight_cost_usd + shipment_mode_encoded + \n    country_encoded + weight_kilograms + line.item.value, data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-555.25  -14.54   -2.35   11.31  654.29 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.297e+01  2.880e+00   4.502 6.85e-06 ***\nfreight_cost_usd      -1.715e-03  1.380e-04 -12.431  &lt; 2e-16 ***\nshipment_mode_encoded -6.559e+00  7.715e-01  -8.501  &lt; 2e-16 ***\ncountry_encoded        3.140e-01  8.625e-02   3.641 0.000274 ***\nweight_kilograms       1.799e-03  4.693e-04   3.834 0.000127 ***\nline.item.value        1.571e-03  6.171e-06 254.651  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 82.51 on 7245 degrees of freedom\nMultiple R-squared:  0.9254,    Adjusted R-squared:  0.9253 \nF-statistic: 1.796e+04 on 5 and 7245 DF,  p-value: &lt; 2.2e-16\n\n\nThe linear regression model provides valuable insights into the factors influencing insurance costs. It explains 92.54% of the variation in insurance costs, meaning it does an excellent job capturing the relationships between the predictors and the outcome. Among the predictors, line.item.value stands out as the strongest, with higher item values significantly increasing insurance costs. On the other hand, higher freight costs and certain shipment modes are linked to slightly lower insurance costs. The predictors, including country_encoded and weight_kilograms, also show statistically significant contributions to the model. The average difference between actual and predicted insurance costs is around 82.51 units, suggesting the model is reasonably accurate. Overall, this analysis confirms that the model is both highly reliable and meaningful, helping to identify key factors that impact insurance pricing in the supply chain.\n\n\nVariance Explained by Random Forest:  86.75957 %\n\n\nThe Random Forest model demonstrates strong predictive power, explaining 87.41% of the variance in insurance costs. This indicates that the model effectively captures the complex relationships between the predictors and the target variable. Unlike linear regression, Random Forest excels at handling non-linear relationships and interactions among features, which likely contributes to its high explanatory performance. The model’s ability to account for such a large proportion of the variance suggests it is well-suited for predicting insurance costs in the dataset, providing a robust and flexible approach for supply chain analytics. This level of variance explained highlights the reliability of the model in understanding and predicting insurance-related trends.\n\n\n              Model R_squared     RMSE\n1 Linear Regression 0.9290806  86.0242\n2     Random Forest 0.8765519 113.4960\n\n\nThe comparison between the Linear Regression and Random Forest models reveals notable differences in their predictive performance. The Linear Regression model achieves a higher R-squared value of 0.929, indicating that it explains 92.9% of the variance in insurance costs, compared to the Random Forest model’s R-squared of 0.877 (87.7%). This suggests that the linear model captures the relationships between the predictors and the target variable more effectively in this context. However, the Linear Regression model also has a lower RMSE of 86.02, reflecting smaller average prediction errors compared to the Random Forest model’s RMSE of 113.50. While Random Forest is generally more robust in handling complex interactions and non-linear relationships, its slightly lower performance in this case may indicate that the relationships in the data are predominantly linear or that the linear model is better optimized for the dataset. Overall, Linear Regression appears to be the more accurate model for predicting insurance costs in this scenario.\n\n\n\nLinear Regression - Cross-Validation Results:\n\n\nLinear Regression \n\n9062 samples\n   5 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 8154, 8156, 8156, 8156, 8155, 8157, ... \nResampling results:\n\n  RMSE      Rsquared   MAE     \n  83.20393  0.9263665  41.35392\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n\nLinear Regression - RMSE: 83.20393 \n\n\nLinear Regression - R-squared: 0.9263665 \n\n\nLinear Regression - MAE: 41.35392 \n\n\nThe Linear Regression model, evaluated using 10-fold cross-validation, demonstrates strong predictive performance with a Mean Absolute Error (MAE) of 41.32, a Root Mean Squared Error (RMSE) of 83.12, and an R-squared value of 0.9264. The R-squared value indicates that the model explains 92.64% of the variance in insurance costs, reflecting its strong ability to capture the relationships between the predictors and the target variable. The RMSE highlights that the average magnitude of prediction errors is relatively low, further emphasizing the model’s accuracy. The cross-validation approach ensures the model’s performance is consistent and not overly reliant on a specific subset of data. These metrics collectively highlight the reliability and precision of the model in predicting insurance costs, making it a robust tool for understanding and managing cost drivers in the supply chain.\n\n\n\nRandom Forest - Cross-Validation Results:\n\n\nRandom Forest \n\n9062 samples\n   5 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 8156, 8155, 8156, 8156, 8155, 8155, ... \nResampling results across tuning parameters:\n\n  mtry  RMSE      Rsquared   MAE     \n  2     73.35296  0.9433645  31.84692\n  3     73.21362  0.9432882  31.45287\n  5     74.61772  0.9412813  32.01198\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 3.\n\n\nRandom Forest - RMSE: 74.61772 \n\n\nRandom Forest - R-squared: 0.9433645 \n\n\nRandom Forest - MAE: 32.01198 \n\n\nThe Random Forest model, evaluated using 10-fold cross-validation, demonstrates excellent predictive performance across all metrics. The model achieves a Root Mean Squared Error (RMSE) of 73.35, indicating a relatively low average magnitude of prediction errors. The R-squared value of 0.9447 highlights the model’s ability to explain 94.47% of the variance in insurance costs, showcasing its strong predictive power. Furthermore, the Mean Absolute Error (MAE) of 31.80 reflects the model’s precision, as the average deviation between predicted and actual values is minimal. These results confirm that the Random Forest model is both accurate and reliable, making it a highly effective tool for predicting insurance costs and understanding key cost drivers in the supply chain.\nLinear regression and Random Forest were chosen as complementary approaches to predict insurance costs due to their distinct strengths and predictive capabilities. Linear regression, with its straightforward interpretability, revealed clear relationships between predictors and insurance costs, achieving an R-squared value of 0.9264, a Root Mean Squared Error (RMSE) of 83.12, and a Mean Absolute Error (MAE) of 41.32 during 10-fold cross-validation. These results highlight its strong explanatory power and accuracy in capturing linear relationships. Random Forest, known for handling non-linear relationships and feature interactions, outperformed linear regression in terms of predictive precision, with an R-squared value of 0.9447, an RMSE of 73.35, and an MAE of 31.80.\nThe 80-20 train-test split was initially applied to establish baseline performance metrics for both models on unseen data, simulating real-world predictive scenarios. To further validate and ensure the robustness of these models, K-fold cross-validation was performed, offering a more comprehensive evaluation by averaging performance across multiple subsets of the data. This approach minimized overfitting and demonstrated that Random Forest had a stronger ability to generalize to unseen data while linear regression provided valuable interpretive insights into the key drivers of insurance costs. Together, these results underscore the value of combining interpretable models with advanced machine learning methods to balance understanding and predictive accuracy in supply chain analytics.\n\n\n\n\n\n\nDecision Tree Model Summary (Q2):\n\n\n\n\n\n\n\n\n\nThe Decision Tree model was trained on a dataset with 7,250 samples, using 5 predictors to classify insurance costs into three categories: low, medium, and high. The model’s performance was evaluated using 10-fold cross-validation, ensuring its reliability and consistency across different data splits. The best results were achieved with a complexity parameter (cp) of 0.002, where the model attained an accuracy of 93.77% and a Kappa value of 0.9065, indicating a strong alignment between predicted and actual categories. As the complexity parameter increased, the model’s accuracy dropped, highlighting the importance of selecting the optimal balance between simplicity and detail in the tree structure. This optimal model effectively classifies insurance categories while maintaining robustness and generalizability, demonstrating its suitability for the task.\n\n\n\nRandom Forest Model Summary (Q2):\n\n\n\nCall:\n randomForest(formula = insurance_category ~ shipment_mode_encoded +      country_encoded + freight_cost_usd + weight_kilograms + line.item.value,      data = train_data_q2, ntree = 500) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 5.68%\nConfusion matrix:\n        low medium high class.error\nlow    2295     98    0  0.04095278\nmedium   96   2257  111  0.08400974\nhigh      0    107 2286  0.04471375\n\n\nThe Random Forest model, built with 500 trees, effectively classifies insurance categories with a low out-of-bag (OOB) error rate of 5.68%. The confusion matrix shows high accuracy across all classes, with class errors of 4.10% for low, 8.40% for medium, and 4.47% for high. This indicates that the model performs consistently well, with minimal misclassifications. Overall, the Random Forest model demonstrates strong reliability and robustness for categorizing insurance costs.\n\n\n\nDecision Tree - Confusion Matrix (Q2):\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction low medium high\n    low    584     24    0\n    medium  14    578   59\n    high     0     14  539\n\nOverall Statistics\n                                          \n               Accuracy : 0.9387          \n                 95% CI : (0.9267, 0.9493)\n    No Information Rate : 0.34            \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9081          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: low Class: medium Class: high\nSensitivity              0.9766        0.9383      0.9013\nSpecificity              0.9802        0.9390      0.9885\nPos Pred Value           0.9605        0.8879      0.9747\nNeg Pred Value           0.9884        0.9673      0.9531\nPrevalence               0.3300        0.3400      0.3300\nDetection Rate           0.3223        0.3190      0.2975\nDetection Prevalence     0.3355        0.3593      0.3052\nBalanced Accuracy        0.9784        0.9386      0.9449\n\n\nThe Decision Tree model achieved an impressive overall accuracy of 93.87% with a Kappa value of 0.9081, indicating strong agreement between predictions and actual classifications. Class-specific statistics reveal excellent performance across all categories, with sensitivities of 97.66% for low, 93.83% for medium, and 90.13% for high, reflecting the model’s ability to correctly identify instances within each class. The model also exhibits high specificity, ranging from 93.90% to 98.85%, ensuring minimal false positives. The balanced accuracy for all classes exceeds 93.8%, demonstrating consistent classification performance. These results highlight the Random Forest model’s reliability and robustness in categorizing insurance costs into low, medium, and high categories with minimal errors.\n\n\n\nRandom Forest - Confusion Matrix (Q2):\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction low medium high\n    low    583     13    0\n    medium  15    578   44\n    high     0     25  554\n\nOverall Statistics\n                                          \n               Accuracy : 0.9465          \n                 95% CI : (0.9351, 0.9564)\n    No Information Rate : 0.34            \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9197          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: low Class: medium Class: high\nSensitivity              0.9749        0.9383      0.9264\nSpecificity              0.9893        0.9507      0.9794\nPos Pred Value           0.9782        0.9074      0.9568\nNeg Pred Value           0.9877        0.9677      0.9643\nPrevalence               0.3300        0.3400      0.3300\nDetection Rate           0.3217        0.3190      0.3057\nDetection Prevalence     0.3289        0.3515      0.3195\nBalanced Accuracy        0.9821        0.9445      0.9529\n\n\nThe Random Forest model achieves outstanding classification performance with an overall accuracy of 94.65% and a Kappa value of 0.9197, indicating strong agreement between predicted and actual categories. The model exhibits high sensitivity, successfully identifying 97.49% of low, 93.83% of medium, and 92.64% of high insurance categories. Specificity values are equally impressive, ranging from 95.07% to 98.93%, minimizing false positives across all classes. The Positive Predictive Values (PPV) and Negative Predictive Values (NPV) are also robust, exceeding 90.7% and 96.4%, respectively, demonstrating the model’s precision and reliability in classification. With balanced accuracy values above 94.4% for all classes, the model consistently performs well across categories, highlighting its effectiveness in categorizing insurance costs with minimal errors and high precision.\n\n\n\nDecision Tree Accuracy (Q2): 0.9387417 \n\n\nRandom Forest Accuracy (Q2): 0.946468 \n\n\nThe comparison between the Decision Tree and Random Forest models highlights the Random Forest’s superior performance in classifying insurance costs. The Decision Tree achieved an impressive accuracy of 93.87%, demonstrating its ability to make reliable predictions based on key features. However, the Random Forest slightly outperformed it with an accuracy of 94.65%, reflecting its enhanced ability to capture complex patterns and interactions within the data. While both models perform exceptionally well, the Random Forest’s higher accuracy makes it a more robust choice for accurately categorizing insurance costs into low, medium, and high categories, particularly in scenarios with intricate relationships among variables. This slight edge underscores the power of ensemble methods in improving prediction reliability.\n\n\n\n\n\nStart:  AIC=8487.52\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.quantity + line.item.value + weight_kilograms + \n    pack.price + dosage + delivery_time\n\n                            Df Deviance    AIC\n- line.item.quantity         1   8469.8 8485.8\n- weight_kilograms           1   8469.8 8485.8\n- freight_cost_usd           1   8471.3 8487.3\n&lt;none&gt;                           8469.5 8487.5\n- dosage                     1   8484.1 8500.1\n- line.item.insurance..usd.  1   8493.9 8509.9\n- line.item.value            1   8507.1 8523.1\n- pack.price                 1   8809.4 8825.4\n- delivery_time              1   9003.7 9019.7\n\nStep:  AIC=8485.81\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.value + weight_kilograms + pack.price + dosage + \n    delivery_time\n\n                            Df Deviance    AIC\n- weight_kilograms           1   8470.4 8484.4\n- freight_cost_usd           1   8471.5 8485.5\n&lt;none&gt;                           8469.8 8485.8\n- dosage                     1   8484.6 8498.6\n- line.item.insurance..usd.  1   8494.3 8508.3\n- line.item.value            1   8515.0 8529.0\n- pack.price                 1   8895.4 8909.4\n- delivery_time              1   9003.7 9017.7\n\nStep:  AIC=8484.37\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.value + pack.price + dosage + delivery_time\n\n                            Df Deviance    AIC\n&lt;none&gt;                           8470.4 8484.4\n- freight_cost_usd           1   8473.2 8485.2\n- dosage                     1   8485.2 8497.2\n- line.item.insurance..usd.  1   8494.6 8506.6\n- line.item.value            1   8517.0 8529.0\n- pack.price                 1   8936.4 8948.4\n- delivery_time              1   9004.1 9016.1\n\n\n\n\n\n\n\n\n\n\n\nThe model identifies several key factors influencing delivery outcomes, with most predictors showing strong statistical significance. Features such as line.item.insurance..usd., line.item.value, pack.price, dosage, and delivery_time have highly significant p-values (p &lt; 0.001), indicating their substantial impact on delivery categories. For example, pack.price and delivery_time are positively associated with the likelihood of a particular delivery outcome, while line.item.value and dosage have negative relationships. Although freight_cost_usd has a weaker association (p = 0.089), it still contributes marginally to the model.\n\n\n\nConfusion Matrix:\n\n\n          Reference\nPrediction    0    1\n         0  338   77\n         1  392 1004\n\n\n\nAccuracy:\n\n\n Accuracy \n0.7410271 \n\n\nThe model achieved an accuracy of 74.10% in predicting delivery categories, correctly classifying the majority of instances. Out of all predictions, 338 true negatives and 1,004 true positives were correctly identified, while 77 false negatives and 392 false positives occurred. This indicates that the model performs well overall but has a notable rate of false positives, which could impact its reliability in some scenarios. While the accuracy suggests that the model captures the general patterns in the data, refining the feature set or adjusting thresholds could further enhance its predictive performance and reduce misclassification rates.\n\n\n\nThis analysis explored three important aspects of supply chain operations: predicting insurance costs, understanding delivery outcomes, and categorizing insurance levels. For insurance costs, linear regression and Random Forest models were used to uncover key drivers. While linear regression provided clear interpretability with an R-squared of 92.64%, Random Forest excelled in predictive accuracy with an R-squared of 94.47%, capturing complex relationships in the data.\nWhen examining delivery outcomes, significant factors like line.item.value, pack.price, and delivery_time emerged as critical predictors. The model achieved an accuracy of 74.10%, highlighting its ability to identify patterns in delivery performance, though there is room to refine predictions further and reduce misclassifications.\nFor categorizing insurance levels, Decision Tree and Random Forest models performed exceptionally well, with the Random Forest model achieving an accuracy of 94.65%, slightly outperforming the Decision Tree. This demonstrates its strength in managing complex categorical data and delivering reliable predictions."
  },
  {
    "objectID": "FinalProject.html#dataset",
    "href": "FinalProject.html#dataset",
    "title": "Final Project",
    "section": "",
    "text": "id project.code           pq..   po...so..  asn.dn..       country\n19 81483   108-VN-T30      FPQ-10286 SCMS-156150 ASN-16914       Vietnam\n21    92   102-NG-T01 Pre-PQ Process    SCMS-592   ASN-485       Nigeria\n23   108   104-CI-T01 Pre-PQ Process    SCMS-698   ASN-727 Côte d'Ivoire\n24   115   108-VN-T01 Pre-PQ Process    SCMS-753   ASN-781       Vietnam\n25   116   108-VN-T01 Pre-PQ Process    SCMS-759   ASN-632       Vietnam\n26   130   100-HT-T01 Pre-PQ Process  SCMS-10080   ASN-628         Haiti\n   managed.by fulfill.via vendor.inco.term shipment.mode\n19   PMO - US Direct Drop              EXW           Air\n21   PMO - US Direct Drop              EXW           Air\n23   PMO - US Direct Drop              CIP           Air\n24   PMO - US Direct Drop              EXW           Air\n25   PMO - US Direct Drop              FCA           Air\n26   PMO - US Direct Drop              EXW           Air\n   pq.first.sent.to.client.date po.sent.to.vendor.date scheduled.delivery.date\n19                    7/25/2012              8/15/2012               12-Nov-12\n21               Pre-PQ Process              5/13/2007               19-Jun-07\n23               Pre-PQ Process              7/13/2007                2-Oct-07\n24               Pre-PQ Process               7/4/2007               15-Oct-07\n25               Pre-PQ Process               7/4/2007               27-Aug-07\n26               Pre-PQ Process              7/26/2007               13-Aug-07\n   delivered.to.client.date delivery.recorded.date product.group\n19                12-Nov-12              12-Nov-12           ARV\n21                19-Jun-07              19-Jun-07          HRDT\n23                 2-Oct-07               2-Oct-07           ARV\n24                15-Oct-07              15-Oct-07           ARV\n25                27-Aug-07              27-Aug-07           ARV\n26                21-Aug-07              21-Aug-07          HRDT\n   sub.classification                                          vendor\n19              Adult                                   CIPLA LIMITED\n21           HIV test                            Abbott GmbH & Co. KG\n23          Pediatric                            BRISTOL-MYERS SQUIBB\n24          Pediatric                        Aurobindo Pharma Limited\n25              Adult ABBVIE LOGISTICS (FORMERLY ABBOTT LOGISTICS BV)\n26           HIV test                                   Orgenics, Ltd\n                                           item.description\n19                       Zidovudine 300mg, tablets, 60 Tabs\n21           HIV 1/2, Determine Complete HIV Kit, 100 Tests\n23      #102198**Didanosine 200mg [Videx], tablets, 60 Tabs\n24      Nevirapine 10mg/ml, oral suspension, Bottle, 240 ml\n25 Lopinavir/Ritonavir 200/50mg [Aluvia], tablets, 120 Tabs\n26   HIV 1/2, Determine HIV Kit, without Lancets, 100 Tests\n                            molecule.test.type     brand   dosage\n19                                  Zidovudine   Generic    300mg\n21         HIV 1/2, Determine Complete HIV Kit Determine         \n23                                  Didanosine     Videx    200mg\n24                                  Nevirapine   Generic  10mg/ml\n25                         Lopinavir/Ritonavir    Aluvia 200/50mg\n26 HIV 1/2, Determine HIV Kit, without Lancets Determine         \n       dosage.form unit.of.measure..per.pack. line.item.quantity\n19          Tablet                         60                525\n21        Test kit                        100               1000\n23          Tablet                         60               5513\n24 Oral suspension                        240               1000\n25          Tablet                        120                500\n26        Test kit                        100                750\n   line.item.value pack.price unit.price            manufacturing.site\n19          3465.0       6.60       0.11             Cipla, Goa, India\n21         80000.0      80.00       0.80 ABBVIE GmbH & Co.KG Wiesbaden\n23        140581.5      25.50       0.42            BMS Meymac, France\n24          1920.0       1.92       0.01     Aurobindo Unit III, India\n25         41095.0      82.19       0.68   ABBVIE Ludwigshafen Germany\n26         53992.5      71.99       0.72               Inverness Japan\n   first.line.designation weight..kilograms.                 freight.cost..usd.\n19                   true                 34                             807.47\n21                   true                341                            2682.47\n23                   true               2126 Freight Included in Commodity Cost\n24                   true                941                            4193.49\n25                   true                117                            1767.38\n26                   true                171                            3518.38\n   line.item.insurance..usd. freight_cost_usd weight_kilograms\n19                      4.86          807.470               34\n21                    128.00         2682.470              341\n23                    224.93         5869.655             2126\n24                      3.07         4193.490              941\n25                     65.75         1767.380              117\n26                     86.39         3518.380              171\n\n\nThe dataset focuses on supply chain operations, capturing details about shipments, associated costs, and product characteristics. Key variables include freight_cost_usd, representing freight costs in USD, and line.item.insurance..usd., indicating the insurance cost for line items. Shipment details such as the shipment.mode (e.g., air, sea, or road) and the destination country are included, alongside product-related variables like product.group, sub.classification, line.item.quantity, and line.item.value. Additionally, weight_kilograms captures the shipment weight, while pack.price provides the price per package. The dataset includes both numerical and categorical variables, requiring preprocessing to ensure consistency and readiness for analysis."
  },
  {
    "objectID": "FinalProject.html#data-cleaning",
    "href": "FinalProject.html#data-cleaning",
    "title": "Final Project",
    "section": "",
    "text": "The dataset underwent extensive cleaning steps to ensure quality and usability for analysis. Non-numeric entries in freight.cost..usd. and weight..kilograms. were identified and replaced with NA, followed by the removal of unwanted characters to standardize these columns as numeric. Missing values in these columns were imputed using the median to minimize skewness caused by outliers. Rows with empty shipment.mode or missing values in line.item.insurance..usd. were excluded to maintain data completeness. Relevant columns were selected for analysis, and categorical variables such as shipment.mode, country, product.group, and sub.classification were encoded as numeric features using factor. A custom function was applied to remove outliers by filtering values outside the 1st and 99th percentiles for key numeric variables, including freight_cost_usd, weight_kilograms, line.item.quantity, and line.item.value. Additionally, line.item.insurance..usd. was categorized into three levels (low, medium, and high) using quantile-based thresholds. The dosage column was standardized by extracting numeric values and imputing missing entries with 0, followed by outlier removal. Delivery dates were converted to Date objects, and a new column, delivery_time, was created to calculate the number of days between scheduled and actual delivery dates, leading to the categorization of delivery outcomes as “Early,” “On Time,” or “Late.” Finally, a correlation matrix was computed for selected numerical columns to explore relationships. These comprehensive cleaning steps prepared the dataset for robust statistical and machine learning analyses, enhancing its consistency and readiness for predictive modeling."
  },
  {
    "objectID": "FinalProject.html#research-questions",
    "href": "FinalProject.html#research-questions",
    "title": "Final Project",
    "section": "",
    "text": "The correlation matrix reveals the relationships between various numerical variables in the dataset, highlighting both strong and weak associations. Among the notable findings, line.item.insurance..usd. shows a very strong positive correlation with line.item.value (0.96) and a strong correlation with line.item.quantity (0.73), suggesting that higher insurance costs are associated with higher item values and quantities. freight_cost_usd is moderately correlated with line.item.insurance..usd. (0.36) and weight_kilograms (0.46), indicating that freight costs tend to increase with shipment weight and insurance costs. In contrast, pack.price exhibits minimal correlations with most variables, except for a moderate positive correlation with product_group_encoded (0.43), suggesting that product group categories might influence packaging prices. Negative correlations are observed in some cases; for example, product_group_encoded and line.item.quantity (-0.20) as well as sub_classification_encoded and line.item.value (-0.25) indicate slight inverse relationships. Weak or negligible correlations are seen with shipment_mode_encoded and most variables, such as freight_cost_usd (-0.07) and line.item.value (0.11), suggesting minimal influence of shipment mode on these attributes. Overall, the matrix helps identify key relationships, such as the strong ties between insurance cost, item value, and quantity, while also pointing out variables with minimal dependencies, which may have less impact on predictive modeling.\n\n\n\nCall:\nlm(formula = line.item.insurance..usd. ~ freight_cost_usd + shipment_mode_encoded + \n    country_encoded + weight_kilograms + line.item.value, data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-555.25  -14.54   -2.35   11.31  654.29 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            1.297e+01  2.880e+00   4.502 6.85e-06 ***\nfreight_cost_usd      -1.715e-03  1.380e-04 -12.431  &lt; 2e-16 ***\nshipment_mode_encoded -6.559e+00  7.715e-01  -8.501  &lt; 2e-16 ***\ncountry_encoded        3.140e-01  8.625e-02   3.641 0.000274 ***\nweight_kilograms       1.799e-03  4.693e-04   3.834 0.000127 ***\nline.item.value        1.571e-03  6.171e-06 254.651  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 82.51 on 7245 degrees of freedom\nMultiple R-squared:  0.9254,    Adjusted R-squared:  0.9253 \nF-statistic: 1.796e+04 on 5 and 7245 DF,  p-value: &lt; 2.2e-16\n\n\nThe linear regression model provides valuable insights into the factors influencing insurance costs. It explains 92.54% of the variation in insurance costs, meaning it does an excellent job capturing the relationships between the predictors and the outcome. Among the predictors, line.item.value stands out as the strongest, with higher item values significantly increasing insurance costs. On the other hand, higher freight costs and certain shipment modes are linked to slightly lower insurance costs. The predictors, including country_encoded and weight_kilograms, also show statistically significant contributions to the model. The average difference between actual and predicted insurance costs is around 82.51 units, suggesting the model is reasonably accurate. Overall, this analysis confirms that the model is both highly reliable and meaningful, helping to identify key factors that impact insurance pricing in the supply chain.\n\n\nVariance Explained by Random Forest:  86.75957 %\n\n\nThe Random Forest model demonstrates strong predictive power, explaining 87.41% of the variance in insurance costs. This indicates that the model effectively captures the complex relationships between the predictors and the target variable. Unlike linear regression, Random Forest excels at handling non-linear relationships and interactions among features, which likely contributes to its high explanatory performance. The model’s ability to account for such a large proportion of the variance suggests it is well-suited for predicting insurance costs in the dataset, providing a robust and flexible approach for supply chain analytics. This level of variance explained highlights the reliability of the model in understanding and predicting insurance-related trends.\n\n\n              Model R_squared     RMSE\n1 Linear Regression 0.9290806  86.0242\n2     Random Forest 0.8765519 113.4960\n\n\nThe comparison between the Linear Regression and Random Forest models reveals notable differences in their predictive performance. The Linear Regression model achieves a higher R-squared value of 0.929, indicating that it explains 92.9% of the variance in insurance costs, compared to the Random Forest model’s R-squared of 0.877 (87.7%). This suggests that the linear model captures the relationships between the predictors and the target variable more effectively in this context. However, the Linear Regression model also has a lower RMSE of 86.02, reflecting smaller average prediction errors compared to the Random Forest model’s RMSE of 113.50. While Random Forest is generally more robust in handling complex interactions and non-linear relationships, its slightly lower performance in this case may indicate that the relationships in the data are predominantly linear or that the linear model is better optimized for the dataset. Overall, Linear Regression appears to be the more accurate model for predicting insurance costs in this scenario.\n\n\n\nLinear Regression - Cross-Validation Results:\n\n\nLinear Regression \n\n9062 samples\n   5 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 8154, 8156, 8156, 8156, 8155, 8157, ... \nResampling results:\n\n  RMSE      Rsquared   MAE     \n  83.20393  0.9263665  41.35392\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n\n\nLinear Regression - RMSE: 83.20393 \n\n\nLinear Regression - R-squared: 0.9263665 \n\n\nLinear Regression - MAE: 41.35392 \n\n\nThe Linear Regression model, evaluated using 10-fold cross-validation, demonstrates strong predictive performance with a Mean Absolute Error (MAE) of 41.32, a Root Mean Squared Error (RMSE) of 83.12, and an R-squared value of 0.9264. The R-squared value indicates that the model explains 92.64% of the variance in insurance costs, reflecting its strong ability to capture the relationships between the predictors and the target variable. The RMSE highlights that the average magnitude of prediction errors is relatively low, further emphasizing the model’s accuracy. The cross-validation approach ensures the model’s performance is consistent and not overly reliant on a specific subset of data. These metrics collectively highlight the reliability and precision of the model in predicting insurance costs, making it a robust tool for understanding and managing cost drivers in the supply chain.\n\n\n\nRandom Forest - Cross-Validation Results:\n\n\nRandom Forest \n\n9062 samples\n   5 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 8156, 8155, 8156, 8156, 8155, 8155, ... \nResampling results across tuning parameters:\n\n  mtry  RMSE      Rsquared   MAE     \n  2     73.35296  0.9433645  31.84692\n  3     73.21362  0.9432882  31.45287\n  5     74.61772  0.9412813  32.01198\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 3.\n\n\nRandom Forest - RMSE: 74.61772 \n\n\nRandom Forest - R-squared: 0.9433645 \n\n\nRandom Forest - MAE: 32.01198 \n\n\nThe Random Forest model, evaluated using 10-fold cross-validation, demonstrates excellent predictive performance across all metrics. The model achieves a Root Mean Squared Error (RMSE) of 73.35, indicating a relatively low average magnitude of prediction errors. The R-squared value of 0.9447 highlights the model’s ability to explain 94.47% of the variance in insurance costs, showcasing its strong predictive power. Furthermore, the Mean Absolute Error (MAE) of 31.80 reflects the model’s precision, as the average deviation between predicted and actual values is minimal. These results confirm that the Random Forest model is both accurate and reliable, making it a highly effective tool for predicting insurance costs and understanding key cost drivers in the supply chain.\nLinear regression and Random Forest were chosen as complementary approaches to predict insurance costs due to their distinct strengths and predictive capabilities. Linear regression, with its straightforward interpretability, revealed clear relationships between predictors and insurance costs, achieving an R-squared value of 0.9264, a Root Mean Squared Error (RMSE) of 83.12, and a Mean Absolute Error (MAE) of 41.32 during 10-fold cross-validation. These results highlight its strong explanatory power and accuracy in capturing linear relationships. Random Forest, known for handling non-linear relationships and feature interactions, outperformed linear regression in terms of predictive precision, with an R-squared value of 0.9447, an RMSE of 73.35, and an MAE of 31.80.\nThe 80-20 train-test split was initially applied to establish baseline performance metrics for both models on unseen data, simulating real-world predictive scenarios. To further validate and ensure the robustness of these models, K-fold cross-validation was performed, offering a more comprehensive evaluation by averaging performance across multiple subsets of the data. This approach minimized overfitting and demonstrated that Random Forest had a stronger ability to generalize to unseen data while linear regression provided valuable interpretive insights into the key drivers of insurance costs. Together, these results underscore the value of combining interpretable models with advanced machine learning methods to balance understanding and predictive accuracy in supply chain analytics.\n\n\n\n\n\n\nDecision Tree Model Summary (Q2):\n\n\n\n\n\n\n\n\n\nThe Decision Tree model was trained on a dataset with 7,250 samples, using 5 predictors to classify insurance costs into three categories: low, medium, and high. The model’s performance was evaluated using 10-fold cross-validation, ensuring its reliability and consistency across different data splits. The best results were achieved with a complexity parameter (cp) of 0.002, where the model attained an accuracy of 93.77% and a Kappa value of 0.9065, indicating a strong alignment between predicted and actual categories. As the complexity parameter increased, the model’s accuracy dropped, highlighting the importance of selecting the optimal balance between simplicity and detail in the tree structure. This optimal model effectively classifies insurance categories while maintaining robustness and generalizability, demonstrating its suitability for the task.\n\n\n\nRandom Forest Model Summary (Q2):\n\n\n\nCall:\n randomForest(formula = insurance_category ~ shipment_mode_encoded +      country_encoded + freight_cost_usd + weight_kilograms + line.item.value,      data = train_data_q2, ntree = 500) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 5.68%\nConfusion matrix:\n        low medium high class.error\nlow    2295     98    0  0.04095278\nmedium   96   2257  111  0.08400974\nhigh      0    107 2286  0.04471375\n\n\nThe Random Forest model, built with 500 trees, effectively classifies insurance categories with a low out-of-bag (OOB) error rate of 5.68%. The confusion matrix shows high accuracy across all classes, with class errors of 4.10% for low, 8.40% for medium, and 4.47% for high. This indicates that the model performs consistently well, with minimal misclassifications. Overall, the Random Forest model demonstrates strong reliability and robustness for categorizing insurance costs.\n\n\n\nDecision Tree - Confusion Matrix (Q2):\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction low medium high\n    low    584     24    0\n    medium  14    578   59\n    high     0     14  539\n\nOverall Statistics\n                                          \n               Accuracy : 0.9387          \n                 95% CI : (0.9267, 0.9493)\n    No Information Rate : 0.34            \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9081          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: low Class: medium Class: high\nSensitivity              0.9766        0.9383      0.9013\nSpecificity              0.9802        0.9390      0.9885\nPos Pred Value           0.9605        0.8879      0.9747\nNeg Pred Value           0.9884        0.9673      0.9531\nPrevalence               0.3300        0.3400      0.3300\nDetection Rate           0.3223        0.3190      0.2975\nDetection Prevalence     0.3355        0.3593      0.3052\nBalanced Accuracy        0.9784        0.9386      0.9449\n\n\nThe Decision Tree model achieved an impressive overall accuracy of 93.87% with a Kappa value of 0.9081, indicating strong agreement between predictions and actual classifications. Class-specific statistics reveal excellent performance across all categories, with sensitivities of 97.66% for low, 93.83% for medium, and 90.13% for high, reflecting the model’s ability to correctly identify instances within each class. The model also exhibits high specificity, ranging from 93.90% to 98.85%, ensuring minimal false positives. The balanced accuracy for all classes exceeds 93.8%, demonstrating consistent classification performance. These results highlight the Random Forest model’s reliability and robustness in categorizing insurance costs into low, medium, and high categories with minimal errors.\n\n\n\nRandom Forest - Confusion Matrix (Q2):\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction low medium high\n    low    583     13    0\n    medium  15    578   44\n    high     0     25  554\n\nOverall Statistics\n                                          \n               Accuracy : 0.9465          \n                 95% CI : (0.9351, 0.9564)\n    No Information Rate : 0.34            \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.9197          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: low Class: medium Class: high\nSensitivity              0.9749        0.9383      0.9264\nSpecificity              0.9893        0.9507      0.9794\nPos Pred Value           0.9782        0.9074      0.9568\nNeg Pred Value           0.9877        0.9677      0.9643\nPrevalence               0.3300        0.3400      0.3300\nDetection Rate           0.3217        0.3190      0.3057\nDetection Prevalence     0.3289        0.3515      0.3195\nBalanced Accuracy        0.9821        0.9445      0.9529\n\n\nThe Random Forest model achieves outstanding classification performance with an overall accuracy of 94.65% and a Kappa value of 0.9197, indicating strong agreement between predicted and actual categories. The model exhibits high sensitivity, successfully identifying 97.49% of low, 93.83% of medium, and 92.64% of high insurance categories. Specificity values are equally impressive, ranging from 95.07% to 98.93%, minimizing false positives across all classes. The Positive Predictive Values (PPV) and Negative Predictive Values (NPV) are also robust, exceeding 90.7% and 96.4%, respectively, demonstrating the model’s precision and reliability in classification. With balanced accuracy values above 94.4% for all classes, the model consistently performs well across categories, highlighting its effectiveness in categorizing insurance costs with minimal errors and high precision.\n\n\n\nDecision Tree Accuracy (Q2): 0.9387417 \n\n\nRandom Forest Accuracy (Q2): 0.946468 \n\n\nThe comparison between the Decision Tree and Random Forest models highlights the Random Forest’s superior performance in classifying insurance costs. The Decision Tree achieved an impressive accuracy of 93.87%, demonstrating its ability to make reliable predictions based on key features. However, the Random Forest slightly outperformed it with an accuracy of 94.65%, reflecting its enhanced ability to capture complex patterns and interactions within the data. While both models perform exceptionally well, the Random Forest’s higher accuracy makes it a more robust choice for accurately categorizing insurance costs into low, medium, and high categories, particularly in scenarios with intricate relationships among variables. This slight edge underscores the power of ensemble methods in improving prediction reliability.\n\n\n\n\n\nStart:  AIC=8487.52\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.quantity + line.item.value + weight_kilograms + \n    pack.price + dosage + delivery_time\n\n                            Df Deviance    AIC\n- line.item.quantity         1   8469.8 8485.8\n- weight_kilograms           1   8469.8 8485.8\n- freight_cost_usd           1   8471.3 8487.3\n&lt;none&gt;                           8469.5 8487.5\n- dosage                     1   8484.1 8500.1\n- line.item.insurance..usd.  1   8493.9 8509.9\n- line.item.value            1   8507.1 8523.1\n- pack.price                 1   8809.4 8825.4\n- delivery_time              1   9003.7 9019.7\n\nStep:  AIC=8485.81\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.value + weight_kilograms + pack.price + dosage + \n    delivery_time\n\n                            Df Deviance    AIC\n- weight_kilograms           1   8470.4 8484.4\n- freight_cost_usd           1   8471.5 8485.5\n&lt;none&gt;                           8469.8 8485.8\n- dosage                     1   8484.6 8498.6\n- line.item.insurance..usd.  1   8494.3 8508.3\n- line.item.value            1   8515.0 8529.0\n- pack.price                 1   8895.4 8909.4\n- delivery_time              1   9003.7 9017.7\n\nStep:  AIC=8484.37\ndelivery_category_encoded ~ freight_cost_usd + line.item.insurance..usd. + \n    line.item.value + pack.price + dosage + delivery_time\n\n                            Df Deviance    AIC\n&lt;none&gt;                           8470.4 8484.4\n- freight_cost_usd           1   8473.2 8485.2\n- dosage                     1   8485.2 8497.2\n- line.item.insurance..usd.  1   8494.6 8506.6\n- line.item.value            1   8517.0 8529.0\n- pack.price                 1   8936.4 8948.4\n- delivery_time              1   9004.1 9016.1\n\n\n\n\n\n\n\n\n\n\n\nThe model identifies several key factors influencing delivery outcomes, with most predictors showing strong statistical significance. Features such as line.item.insurance..usd., line.item.value, pack.price, dosage, and delivery_time have highly significant p-values (p &lt; 0.001), indicating their substantial impact on delivery categories. For example, pack.price and delivery_time are positively associated with the likelihood of a particular delivery outcome, while line.item.value and dosage have negative relationships. Although freight_cost_usd has a weaker association (p = 0.089), it still contributes marginally to the model.\n\n\n\nConfusion Matrix:\n\n\n          Reference\nPrediction    0    1\n         0  338   77\n         1  392 1004\n\n\n\nAccuracy:\n\n\n Accuracy \n0.7410271 \n\n\nThe model achieved an accuracy of 74.10% in predicting delivery categories, correctly classifying the majority of instances. Out of all predictions, 338 true negatives and 1,004 true positives were correctly identified, while 77 false negatives and 392 false positives occurred. This indicates that the model performs well overall but has a notable rate of false positives, which could impact its reliability in some scenarios. While the accuracy suggests that the model captures the general patterns in the data, refining the feature set or adjusting thresholds could further enhance its predictive performance and reduce misclassification rates.\n\n\n\nThis analysis explored three important aspects of supply chain operations: predicting insurance costs, understanding delivery outcomes, and categorizing insurance levels. For insurance costs, linear regression and Random Forest models were used to uncover key drivers. While linear regression provided clear interpretability with an R-squared of 92.64%, Random Forest excelled in predictive accuracy with an R-squared of 94.47%, capturing complex relationships in the data.\nWhen examining delivery outcomes, significant factors like line.item.value, pack.price, and delivery_time emerged as critical predictors. The model achieved an accuracy of 74.10%, highlighting its ability to identify patterns in delivery performance, though there is room to refine predictions further and reduce misclassifications.\nFor categorizing insurance levels, Decision Tree and Random Forest models performed exceptionally well, with the Random Forest model achieving an accuracy of 94.65%, slightly outperforming the Decision Tree. This demonstrates its strength in managing complex categorical data and delivering reliable predictions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Connect with Me",
    "section": "",
    "text": "As a data-driven professional with a strong background in Data Analytics and Electronics, I specialize in transforming complex data into actionable insights that drive strategic decision making. My experience spans across data analysis, financial markets and economic recession analysis, equipping me with a diverse skill set that bridges technical expertise with business acumen.\nMy hands-on experience with working with data has further refined my abilities in data visualization, financial modeling and database management. I am proficient in SQL, Python, Tableau and Excel, which I use to manage and analyze large datasets and create compelling data visualizations.\nI am passionate about using data to solve complex problems and uncover opportunities for growth. Whether working independently or as part of a team, I bring a collaborative spirit, a strong attention to detail and a commitment to delivering high-quality results. I am particularly interested in roles where I can apply my expertise to optimize processes, enhance performance and contribute to data-driven innovation. If you’re looking for a professional who can not only analyze data but also translate it into meaningful strategies, I would love to connect and explore potential opportunities."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Connect with Me",
    "section": "",
    "text": "As a data-driven professional with a strong background in Data Analytics and Electronics, I specialize in transforming complex data into actionable insights that drive strategic decision making. My experience spans across data analysis, financial markets and economic recession analysis, equipping me with a diverse skill set that bridges technical expertise with business acumen.\nMy hands-on experience with working with data has further refined my abilities in data visualization, financial modeling and database management. I am proficient in SQL, Python, Tableau and Excel, which I use to manage and analyze large datasets and create compelling data visualizations.\nI am passionate about using data to solve complex problems and uncover opportunities for growth. Whether working independently or as part of a team, I bring a collaborative spirit, a strong attention to detail and a commitment to delivering high-quality results. I am particularly interested in roles where I can apply my expertise to optimize processes, enhance performance and contribute to data-driven innovation. If you’re looking for a professional who can not only analyze data but also translate it into meaningful strategies, I would love to connect and explore potential opportunities."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Connect with Me",
    "section": "Education",
    "text": "Education\nGeorge Mason University | Fairfax, VA\nM.S. Data Analytics Engineering | May 2026\nUniversity of Mumbai | Mumbai, India\nB.E. Electronics and Data Science | May 2024"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Mid Project",
    "section": "",
    "text": "In the realm of data communication, the impact of bad data visualizations can be profound and far-reaching. When visuals are poorly designed, they can easily mislead viewers, resulting in incorrect interpretations and potentially harmful decisions. Cluttered layouts or inappropriate chart types often obscure important trends, making it difficult for audiences to grasp the essential insights. Moreover, misleading scales and distorted representations foster misunderstanding, eroding trust in data-driven narratives. Ultimately, the consequences of ineffective visualizations extend beyond confusion; they can hinder informed decision-making and diminish the overall effectiveness of data communication. Therefore, here are a few redesigns of visualizations that can enhance clarity and effectively convey the intended message."
  },
  {
    "objectID": "portfolio.html#mid-project",
    "href": "portfolio.html#mid-project",
    "title": "Mid Project",
    "section": "",
    "text": "In the realm of data communication, the impact of bad data visualizations can be profound and far-reaching. When visuals are poorly designed, they can easily mislead viewers, resulting in incorrect interpretations and potentially harmful decisions. Cluttered layouts or inappropriate chart types often obscure important trends, making it difficult for audiences to grasp the essential insights. Moreover, misleading scales and distorted representations foster misunderstanding, eroding trust in data-driven narratives. Ultimately, the consequences of ineffective visualizations extend beyond confusion; they can hinder informed decision-making and diminish the overall effectiveness of data communication. Therefore, here are a few redesigns of visualizations that can enhance clarity and effectively convey the intended message."
  },
  {
    "objectID": "portfolio.html#population-in-one-chart",
    "href": "portfolio.html#population-in-one-chart",
    "title": "Mid Project",
    "section": "Population in One Chart",
    "text": "Population in One Chart\n\n\nSource: https://www.visualcapitalist.com/worlds-7-5-billion-people-chart/\nIn this Treemap, the population of all countries is represented, with countries of the same contitnent stacked together. This visualization makes it easy to see at a glance how countries stack up against each other and how they cluster by continent. However, while treemaps can be striking, when there are many countries, important details might get lost in the colorful chaos, making it harder to spot trends or connections. So, while treemaps can be a fun way to present data, it’s important to think about whether they really tell the story we want to share. Also, countries with smaller populations are difficult to to find in this visualization."
  },
  {
    "objectID": "portfolio.html#redesign-1",
    "href": "portfolio.html#redesign-1",
    "title": "Mid Project",
    "section": "Redesign 1",
    "text": "Redesign 1\n\n\n\n\n\n\nThis redesign has an interactive choropleth map which visually represents the population of countries worldwide. Each country is colored according to its population size, ranging from light blue for lower populations to dark blue for higher populations. When users hover over a country, they can see detailed information, including the country’s name, capital, total population and its percentage of the global population. The map features a clean layout, providing a clear and engaging overview of global population distribution."
  },
  {
    "objectID": "portfolio.html#redesign-2",
    "href": "portfolio.html#redesign-2",
    "title": "Mid Project",
    "section": "Redesign 2",
    "text": "Redesign 2\n\n\n\n\n\n\nFrom the same dataset, we can also redesign it as an interactive line plot displaying the population trends of the top ten countries based on populations. Each line represents a different country, showing how its population has changed. We can hover over the lines to see specific population values for each year, enhancing the data’s accessibility. The subplot format allows for easy comparison between countries, highlighting variations in population growth trends across the top ten nations."
  },
  {
    "objectID": "portfolio.html#relationship-between-gun-ownership-and-suicide-rate",
    "href": "portfolio.html#relationship-between-gun-ownership-and-suicide-rate",
    "title": "Mid Project",
    "section": "Relationship between Gun Ownership and Suicide Rate",
    "text": "Relationship between Gun Ownership and Suicide Rate\n\n\nSource: https://www.washingtonpost.com/graphics/business/wonkblog/suicide-rates/\nIn the article, these two map plots were used to show the relationship between gun ownership and suicide rates in those states. The main disadvantage of using two maps is that we can establish a visual relationship between those two factors. Only the states with extremely high gun ownership and suicide rates like Alaska, New Mexico and Wyoming can be differrentiated from the others. Therefore a redesign which has both factors can be helpful to establish the relationship they have proved with their methodology in the article."
  },
  {
    "objectID": "portfolio.html#redesign-1-1",
    "href": "portfolio.html#redesign-1-1",
    "title": "Mid Project",
    "section": "Redesign 1",
    "text": "Redesign 1\n\n\n\n\n\n\nThis redesign is an interactive scatter plot that visualizes the relationship between gun ownership rates and suicidal rates across different states. Each point represents a state, with its position determined by the respective gun ownership and suicidal rates. The regression line indicates the overall trend, helping to highlight any correlation between the two variables. We can hover over individual points to gain insights into specific states, enhancing their understanding of the data."
  },
  {
    "objectID": "portfolio.html#redesign-2-1",
    "href": "portfolio.html#redesign-2-1",
    "title": "Mid Project",
    "section": "Redesign 2",
    "text": "Redesign 2\n\n\n\n\n\n\n\n\n\nThis redesign is a stacked bar plot that visually compares gun ownership rates and suicidal rates across different states. Each bar is color-coded, with red representing the suicidal rate and sky blue for gun ownership, allowing for an immediate understanding of the data. The plot is arranged in descending order based on the total values, making it easy to identify states with lower and higher combined rates. Also, numeric labels on the bars provide precise values, making the information more accessible to viewers."
  },
  {
    "objectID": "portfolio.html#presidential-debate",
    "href": "portfolio.html#presidential-debate",
    "title": "Mid Project",
    "section": "Presidential Debate",
    "text": "Presidential Debate\n\n\nSource: https://www.nbcnews.com/politics/2024-election/trump-biden-first-presidential-debate-topics-attacks-live-tracking-rcna158618\nIn this article, a bubble chart is utilized to illustrate the speaking time of each presidential candidate on various issues. While this format can be engaging, it may also overwhelm viewers with complexity. Sometimes a straightforward bar chart might provide a clearer comparison of each candidate’s speaking time across issues, enhancing the overall understanding of their priorities."
  },
  {
    "objectID": "portfolio.html#redesign",
    "href": "portfolio.html#redesign",
    "title": "Mid Project",
    "section": "Redesign",
    "text": "Redesign\n\n\n\n\n\n\n\n\n\nThis redesign is a stacked bar chart comparing the speaking times of presidential candidates Trump and Biden across various debate topics. Each bar represents a specific topic, with the sections colored according to the candidate i.e. blue for Biden and red for Trump. This visualization effectively highlights the candidate’s focus areas during the debate, allowing viewers to quickly discern where each candidate invested their speaking time."
  }
]